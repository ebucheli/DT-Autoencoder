{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['class','age','menopause','tumor-size',\n",
    "        'inv-nodes','node-caps','deg-malig',\n",
    "        'breast','breast-quad','irradiat']\n",
    "\n",
    "df = pd.read_csv('./datasets/breast-cancer.data',names = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all columns categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_col in cols[1:]:\n",
    "    df[this_col] = df[this_col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get mapping dict from label names to categorical indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dicts_list = []\n",
    "\n",
    "for col in df.columns:\n",
    "    labels = np.unique(df[col])\n",
    "    map_dicts_list.append(dict([[val,i] for i,val in enumerate(labels)]))\n",
    "    \n",
    "map_dicts_v2 = dict([[att,this_dict] for att,this_dict in zip(df.columns,map_dicts_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get instances for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance of first class: 201\n",
      "Instance of second class: 85\n"
     ]
    }
   ],
   "source": [
    "print('Instance of first class:', np.sum(df['class'] == 'no-recurrence-events'))\n",
    "print('Instance of second class:', np.sum(df['class'] == 'recurrence-events'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make normal and anomalies partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oc = df[df['class'] == 'no-recurrence-events']\n",
    "df_oc = df_oc.drop('class',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anom = df[df['class'] == 'recurrence-events']\n",
    "df_anom = df_anom.drop('class',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make OH versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oh = pd.get_dummies(df,columns = cols[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_cols = df_oh.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oc_oh = df_oh[df_oh['class'] == 'no-recurrence-events']\n",
    "df_oc_oh = df_oc_oh.drop('class',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anom_oh = df_oh[df_oh['class'] == 'recurrence-events']\n",
    "df_anom_oh = df_anom_oh.drop('class',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for col in cols[1:]:\n",
    "    \n",
    "    this_X = df_oc_oh.loc[:,[f for f in df_oc_oh.columns if not f.startswith(col)]]\n",
    "    this_y = df_oc.loc[:,col]\n",
    "    \n",
    "    xs.append(this_X)\n",
    "    ys.append(this_y)\n",
    "    \n",
    "    this_clf = tree.DecisionTreeClassifier()\n",
    "    this_clf.fit(this_X,this_y)\n",
    "    clfs.append(this_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (15,15))\n",
    "#my_tree = tree.plot_tree(clfs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial weights for layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_init = []\n",
    "w2_init = []\n",
    "\n",
    "for i,clf in enumerate(clfs):\n",
    "    w1_init.append(recall_score(ys[i],clf.predict(xs[i]),average=None))\n",
    "    w2_init.append(clf.score(xs[i],ys[i]))\n",
    "    \n",
    "w2_init = np.array(w2_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.        , 0.95238095, 0.93650794, 0.92957746, 0.85      ,\n",
       "        0.8       ]),\n",
       " array([0.9893617 , 1.        , 0.97058824]),\n",
       " array([0.85714286, 0.85185185, 0.86956522, 0.85294118, 0.66666667,\n",
       "        0.65714286, 0.66666667, 0.625     , 0.5       , 0.5       ,\n",
       "        0.2       ]),\n",
       " array([1.        , 1.        , 0.66666667, 0.84210526, 1.        ,\n",
       "        1.        ]),\n",
       " array([1.  , 1.  , 0.96]),\n",
       " array([0.96610169, 0.93137255, 0.85      ]),\n",
       " array([0.95145631, 0.76530612]),\n",
       " array([1.        , 0.93333333, 0.81690141, 0.77777778, 0.6       ]),\n",
       " array([1.        , 0.91891892])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91542289, 0.9800995 , 0.73134328, 0.9800995 , 0.99502488,\n",
       "       0.92537313, 0.86069652, 0.85074627, 0.98507463])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some network functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_l1(x_prime,weights,indxs):\n",
    "    \n",
    "    my_res = np.zeros((len(x_prime)))\n",
    "\n",
    "    for i,this_x_prime in enumerate(x_prime):\n",
    "        \n",
    "        if indxs[i] >= len(weights):\n",
    "            indxs[i] -= 1\n",
    "        this_x_wrong = np.delete(this_x_prime,indxs[i])\n",
    "        w_wrong = np.delete(weights,indxs[i])\n",
    "        my_res[i] = this_x_prime[indxs[i]]*weights[indxs[i]]-np.mean(this_x_wrong*w_wrong)\n",
    "        \n",
    "    return my_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Normal Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_y_hat = []\n",
    "\n",
    "for i, clf in enumerate(clfs):\n",
    "    dt_y_hat.append(clf.predict_proba(xs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Loss = 0.7111\n",
      "Iteration 11: Loss = 0.6451\n",
      "Iteration 21: Loss = 0.5792\n",
      "Iteration 31: Loss = 0.5132\n",
      "Iteration 41: Loss = 0.4473\n",
      "Iteration 51: Loss = 0.3813\n",
      "Iteration 61: Loss = 0.3153\n",
      "Iteration 71: Loss = 0.2494\n",
      "Iteration 81: Loss = 0.1834\n",
      "Iteration 91: Loss = 0.1174\n",
      "Iteration 100: Loss = 0.0581\n"
     ]
    }
   ],
   "source": [
    "w1 = deepcopy(w1_init)\n",
    "w2 = deepcopy(w2_init)\n",
    "\n",
    "lr = 0.001\n",
    "iterations = 100\n",
    "lrw1 = 0.01\n",
    "\n",
    "losses = []\n",
    "accs = []\n",
    "\n",
    "y_norm = np.ones(len(df_oc_oh))\n",
    "\n",
    "for i in range(iterations):\n",
    "    \n",
    "    hl1_this = np.zeros((len(df_oc_oh),len(cols[1:])))\n",
    "    \n",
    "    for j,x_prime in enumerate(dt_y_hat):\n",
    "\n",
    "        x_prime_prime = np.argmax(x_prime*w1[j])\n",
    "        \n",
    "        label = cols[1:][j]\n",
    "        num_labels = [map_dicts_v2[label][f] for f in ys[j]]\n",
    "        \n",
    "        for k in np.unique(num_labels):\n",
    "            \n",
    "            if k >= x_prime.shape[1]:\n",
    "                break\n",
    "            \n",
    "            indices = np.where(num_labels==k)\n",
    "            this_probs = x_prime[indices]\n",
    "            x_prime_this_this = x_prime[indices]\n",
    "\n",
    "            grad_wj = np.mean(x_prime_this_this[:,k])\n",
    "            grad_wl = np.mean(-(1/len(np.unique(num_labels)))*np.delete(x_prime_this_this,k,axis = 1),axis = 0)\n",
    "    \n",
    "            w1[j][k] = w1[j][k] - lrw1*grad_wj\n",
    "            \n",
    "            for this_indx in [f for f in np.arange(np.max(num_labels)) if f != k]:\n",
    "                \n",
    "                #print('\\t\\t',this_indx)\n",
    "                if this_indx < k:\n",
    "                    grad_indx = this_indx\n",
    "                elif this_indx > k:\n",
    "                    grad_indx = this_indx-1\n",
    "                    \n",
    "                w1[j][this_indx] = w1[j][grad_indx] - lrw1*grad_wl[grad_indx]\n",
    "    \n",
    "    this_loss = []\n",
    "    \n",
    "    for j,x_prime in enumerate(dt_y_hat):\n",
    "        \n",
    "        label = cols[1:][j]\n",
    "        num_labels = [map_dicts_v2[label][f] for f in ys[j]]\n",
    "        hl1_this[:,j] = neuron_l1(x_prime,w1[j],num_labels)\n",
    "    \n",
    "        this_loss.append(np.mean(hl1_this[:,j]))\n",
    "    \n",
    "    if i % 10 == 0 or i == iterations-1:\n",
    "        print('Iteration {}: Loss = {:0.4f}'.format(i+1,np.mean(this_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_norm = []\n",
    "\n",
    "for i, clf in enumerate(clfs):\n",
    "    dt_norm.append(clf.predict_proba(xs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl1_this_all = np.zeros((len(df_oh_x),len(cols[1:])))\n",
    "preds = []\n",
    "predsv2 = []\n",
    "for j,x_prime in enumerate(dt_norm):\n",
    "        \n",
    "        label = cols[1:][j]\n",
    "        num_labels = [map_dicts_v2[label][f] for f in ys[j]]\n",
    "        #preds.append(np.argmax(x_prime*w1_init[j],axis = 1))\n",
    "        #predsv2.append(np.argmax(x_prime*w1[j],axis = 1))\n",
    "        \n",
    "        preds.append(np.mean(neuron_l1(x_prime,w1[j],num_labels)))\n",
    "        predsv2.append((neuron_l1(x_prime,w1_init[j],num_labels)))\n",
    "        #hl1_this_all[:,j] = neuron_l1(x_prime,w1[j],num_labels)\n",
    "        \n",
    "#this_y_hat_all = sigmoid(np.dot(hl1_this_all,w2_init))\n",
    "#np.mean((this_y_hat_all >= 0.5)==y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058082042136220896"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7029285512671855"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predsv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_oh.drop('class',axis = 1)\n",
    "y_all = 1 - np.array([map_dicts_v2['class'][f] for f in df_oh['class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_test = []\n",
    "ys_test = []\n",
    "\n",
    "for col in cols[1:]:\n",
    "    \n",
    "    this_X = df_oh_x.loc[:,[f for f in df_oh_x.columns if not f.startswith(col)]]\n",
    "    this_y = df.loc[:,col]\n",
    "    \n",
    "    xs_test.append(this_X)\n",
    "    ys_test.append(this_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_all = []\n",
    "\n",
    "for i, clf in enumerate(clfs):\n",
    "    dt_all.append(clf.predict_proba(xs_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl1_this_all = np.zeros((len(df_oh_x),len(cols[1:])))\n",
    "preds = []\n",
    "predsv2 = []\n",
    "for j,x_prime in enumerate(dt_all):\n",
    "        \n",
    "        label = cols[1:][j]\n",
    "        num_labels = [map_dicts_v2[label][f] for f in ys_test[j]]\n",
    "        #preds.append(np.argmax(x_prime*w1_init[j],axis = 1))\n",
    "        #predsv2.append(np.argmax(x_prime*w1[j],axis = 1))\n",
    "        \n",
    "        preds.append(neuron_l1(x_prime,w1[j],num_labels))\n",
    "        predsv2.append(neuron_l1(x_prime,w1_init[j],num_labels))\n",
    "        #hl1_this_all[:,j] = neuron_l1(x_prime,w1[j],num_labels)\n",
    "        \n",
    "#this_y_hat_all = sigmoid(np.dot(hl1_this_all,w2_init))\n",
    "#np.mean((this_y_hat_all >= 0.5)==y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "0.3189852024444505\n",
      "0.6262055823675542\n",
      "menopause\n",
      "0.0039048784000786495\n",
      "0.84585736541306\n",
      "tumor-size\n",
      "0.05297200857209073\n",
      "0.3679870857726783\n",
      "inv-nodes\n",
      "0.03408878632748287\n",
      "0.7201509017298492\n",
      "node-caps\n",
      "-0.009259436469963427\n",
      "0.8275874125874126\n",
      "deg-malig\n",
      "0.030535814137165083\n",
      "0.5868566406452748\n",
      "breast\n",
      "0.03427624624118668\n",
      "0.3754791688068883\n",
      "breast-quad\n",
      "-0.08987398331722898\n",
      "-0.09090728976292357\n",
      "irradiat\n",
      "0.014222552332310671\n",
      "0.7324702324702325\n"
     ]
    }
   ],
   "source": [
    "for i,col in enumerate(cols[1:]):\n",
    "    print(col)\n",
    "    print(np.mean(preds[i]))\n",
    "    print(np.mean(predsv2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.        , 0.95238095, 0.93650794, 0.92957746, 0.85      ,\n",
       "        0.8       ]),\n",
       " array([0.9893617 , 1.        , 0.97058824]),\n",
       " array([0.85714286, 0.85185185, 0.86956522, 0.85294118, 0.66666667,\n",
       "        0.65714286, 0.66666667, 0.625     , 0.5       , 0.5       ,\n",
       "        0.2       ]),\n",
       " array([1.        , 1.        , 0.66666667, 0.84210526, 1.        ,\n",
       "        1.        ]),\n",
       " array([1.  , 1.  , 0.96]),\n",
       " array([0.96610169, 0.93137255, 0.85      ]),\n",
       " array([0.95145631, 0.76530612]),\n",
       " array([1.        , 0.93333333, 0.81690141, 0.77777778, 0.6       ]),\n",
       " array([1.        , 0.91891892])]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1_init"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
