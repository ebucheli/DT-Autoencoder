{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['class','age','menopause','tumor-size',\n",
    "        'inv-nodes','node-caps','deg-malig',\n",
    "        'breast','breast-quad','irradiat']\n",
    "\n",
    "df = pd.read_csv('./datasets/breast-cancer.data',names = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all columns categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_col in cols[1:]:\n",
    "    df[this_col] = df[this_col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get mapping dict from label names to categorical indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dicts_list = []\n",
    "\n",
    "for col in df.columns:\n",
    "    labels = np.unique(df[col])\n",
    "    map_dicts_list.append(dict([[val,i] for i,val in enumerate(labels)]))\n",
    "    \n",
    "map_dicts_v2 = dict([[att,this_dict] for att,this_dict in zip(df.columns,map_dicts_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get instances for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance of first class: 201\n",
      "Instance of second class: 85\n"
     ]
    }
   ],
   "source": [
    "print('Instance of first class:', np.sum(df['class'] == 'no-recurrence-events'))\n",
    "print('Instance of second class:', np.sum(df['class'] == 'recurrence-events'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make normal and anomalies partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oc = df[df['class'] == 'no-recurrence-events']\n",
    "df_oc = df_oc.drop('class',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anom = df[df['class'] == 'recurrence-events']\n",
    "df_anom = df_anom.drop('class',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make OH versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oh = pd.get_dummies(df,columns = cols[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_cols = df_oh.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oc_oh = df_oh[df_oh['class'] == 'no-recurrence-events']\n",
    "df_oc_oh = df_oc_oh.drop('class',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anom_oh = df_oh[df_oh['class'] == 'recurrence-events']\n",
    "df_anom_oh = df_anom_oh.drop('class',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([map_dicts_v2[label][f] for f in ys[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for col in cols[1:]:\n",
    "    \n",
    "    this_X = df_oc_oh.loc[:,[f for f in df_oc_oh.columns if not f.startswith(col)]]\n",
    "    this_y = df_oc.loc[:,col]\n",
    "    \n",
    "    xs.append(this_X)\n",
    "    ys.append(this_y)\n",
    "    \n",
    "    this_clf = tree.DecisionTreeClassifier()\n",
    "    this_clf.fit(this_X,this_y)\n",
    "    clfs.append(this_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (15,15))\n",
    "#my_tree = tree.plot_tree(clfs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial weights for layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_init = []\n",
    "w2_init = []\n",
    "\n",
    "for i,clf in enumerate(clfs):\n",
    "    w1_init.append(recall_score(ys[i],clf.predict(xs[i]),average=None))\n",
    "    w2_init.append(clf.score(xs[i],ys[i]))\n",
    "    \n",
    "w2_init = np.array(w2_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.        , 0.95238095, 0.93650794, 0.92957746, 0.85      ,\n",
       "        0.8       ]),\n",
       " array([0.9893617 , 1.        , 0.97058824]),\n",
       " array([0.85714286, 0.85185185, 0.86956522, 0.85294118, 0.66666667,\n",
       "        0.65714286, 0.66666667, 0.625     , 0.5       , 0.5       ,\n",
       "        0.2       ]),\n",
       " array([1.        , 1.        , 0.66666667, 0.84210526, 1.        ,\n",
       "        1.        ]),\n",
       " array([1.  , 1.  , 0.96]),\n",
       " array([0.96610169, 0.93137255, 0.85      ]),\n",
       " array([0.95145631, 0.76530612]),\n",
       " array([1.        , 0.93333333, 0.81690141, 0.77777778, 0.6       ]),\n",
       " array([1.        , 0.91891892])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91542289, 0.9800995 , 0.73134328, 0.9800995 , 0.99502488,\n",
       "       0.92537313, 0.86069652, 0.85074627, 0.98507463])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_init = np.zeros((len(w2_init)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some network functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_l1(x_prime,weights,bias,indxs):\n",
    "    \n",
    "    my_res = np.zeros((len(x_prime)))\n",
    "\n",
    "    for i,this_x_prime in enumerate(x_prime):\n",
    "        \n",
    "        if indxs[i] >= len(weights):\n",
    "            indxs[i] -= 1\n",
    "        this_x_wrong = np.delete(this_x_prime,indxs[i])\n",
    "        w_wrong = np.delete(weights,indxs[i])\n",
    "        my_res[i] = sigmoid(this_x_prime[indxs[i]]*weights[indxs[i]]-np.mean(this_x_wrong*w_wrong)+bias)\n",
    "        \n",
    "    return my_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_y_hat = []\n",
    "\n",
    "for i, clf in enumerate(clfs):\n",
    "    dt_y_hat.append(clf.predict_proba(xs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "\tAttribute 1: 0.6934\n",
      "\tAttribute 2: 0.7237\n",
      "\tAttribute 3: 0.6216\n",
      "\tAttribute 4: 0.6968\n",
      "\tAttribute 5: 0.7342\n",
      "\tAttribute 6: 0.6936\n",
      "\tAttribute 7: 0.6405\n",
      "\tAttribute 8: 0.4734\n",
      "\tAttribute 9: 0.7268\n",
      "Iteration 51:\n",
      "\tAttribute 1: 0.7785\n",
      "\tAttribute 2: 0.8436\n",
      "\tAttribute 3: 0.6801\n",
      "\tAttribute 4: 0.8334\n",
      "\tAttribute 5: 0.8784\n",
      "\tAttribute 6: 0.7922\n",
      "\tAttribute 7: 0.7355\n",
      "\tAttribute 8: 0.4843\n",
      "\tAttribute 9: 0.8657\n",
      "Iteration 101:\n",
      "\tAttribute 1: 0.8288\n",
      "\tAttribute 2: 0.8944\n",
      "\tAttribute 3: 0.7270\n",
      "\tAttribute 4: 0.8719\n",
      "\tAttribute 5: 0.9198\n",
      "\tAttribute 6: 0.8425\n",
      "\tAttribute 7: 0.7810\n",
      "\tAttribute 8: 0.4952\n",
      "\tAttribute 9: 0.9089\n",
      "Iteration 151:\n",
      "\tAttribute 1: 0.8605\n",
      "\tAttribute 2: 0.9202\n",
      "\tAttribute 3: 0.7642\n",
      "\tAttribute 4: 0.8893\n",
      "\tAttribute 5: 0.9389\n",
      "\tAttribute 6: 0.8718\n",
      "\tAttribute 7: 0.8052\n",
      "\tAttribute 8: 0.5062\n",
      "\tAttribute 9: 0.9294\n",
      "Iteration 201:\n",
      "\tAttribute 1: 0.8821\n",
      "\tAttribute 2: 0.9354\n",
      "\tAttribute 3: 0.7937\n",
      "\tAttribute 4: 0.8995\n",
      "\tAttribute 5: 0.9500\n",
      "\tAttribute 6: 0.8908\n",
      "\tAttribute 7: 0.8197\n",
      "\tAttribute 8: 0.5172\n",
      "\tAttribute 9: 0.9415\n",
      "Iteration 251:\n",
      "\tAttribute 1: 0.8977\n",
      "\tAttribute 2: 0.9454\n",
      "\tAttribute 3: 0.8176\n",
      "\tAttribute 4: 0.9064\n",
      "\tAttribute 5: 0.9575\n",
      "\tAttribute 6: 0.9041\n",
      "\tAttribute 7: 0.8292\n",
      "\tAttribute 8: 0.5281\n",
      "\tAttribute 9: 0.9495\n",
      "Iteration 300:\n",
      "\tAttribute 1: 0.9093\n",
      "\tAttribute 2: 0.9522\n",
      "\tAttribute 3: 0.8367\n",
      "\tAttribute 4: 0.9116\n",
      "\tAttribute 5: 0.9628\n",
      "\tAttribute 6: 0.9137\n",
      "\tAttribute 7: 0.8358\n",
      "\tAttribute 8: 0.5387\n",
      "\tAttribute 9: 0.9551\n"
     ]
    }
   ],
   "source": [
    "w1 = deepcopy(w1_init)\n",
    "w2 = deepcopy(w2_init)\n",
    "b1 = deepcopy(bias_init)\n",
    "\n",
    "lr = 0.001\n",
    "iterations = 300\n",
    "lrw1 = 0.001\n",
    "\n",
    "losses = []\n",
    "accs = []\n",
    "\n",
    "y_norm = np.ones(len(df_oc_oh))\n",
    "\n",
    "for i in range(iterations):\n",
    "    \n",
    "    hl1_this = np.zeros((len(df_oc_oh),len(cols[1:])))\n",
    "    \n",
    "    for j,x_prime in enumerate(dt_y_hat):\n",
    "\n",
    "        x_prime_prime = x_prime*w1[j]\n",
    "        \n",
    "        label = cols[1:][j]\n",
    "        num_labels = [map_dicts_v2[label][f] for f in ys[j]]\n",
    "        \n",
    "        for k in np.unique(num_labels):\n",
    "            \n",
    "            if k >= x_prime.shape[1]:\n",
    "                break\n",
    "            \n",
    "            indices = np.where(num_labels==k)\n",
    "            this_probs = x_prime[indices]\n",
    "            x_prime_this_this = x_prime[indices]\n",
    "            x_prime_prime_this_this = x_prime_prime[indices]\n",
    "            \n",
    "            edo = neuron_l1(x_prime_this_this,w1[j],b1[j],np.ones((len(x_prime_this_this)),dtype = int)*k)\n",
    "            #print(edo.shape)\n",
    "            #break\n",
    "            \n",
    "            grad_wj = np.dot(edo*(1-edo),x_prime_this_this[:,k])\n",
    "            grad_bias = np.mean(edo*(1-edo))\n",
    "            \n",
    "            #grad_wj = np.dot(x_prime_prime_this_this[:,k]*(1-x_prime_prime_this_this[:,k]),x_prime_this_this[:,k])\n",
    "            #grad_wl = np.mean(-(1/len(np.unique(num_labels)))*np.delete(x_prime_this_this,k,axis = 1),axis = 0)\n",
    "    \n",
    "            w1[j][k] = w1[j][k] + lrw1*grad_wj\n",
    "            b1[j] = b1[j] + lrw1*grad_bias\n",
    "            #for this_indx in [f for f in np.arange(np.max(num_labels)) if f != k]:\n",
    "                \n",
    "            #    if this_indx < k:\n",
    "            #        grad_indx = this_indx\n",
    "            #    elif this_indx > k:\n",
    "            #        grad_indx = this_indx-1\n",
    "                    \n",
    "            #    w1[j][this_indx] = w1[j][grad_indx] - lrw1*grad_wl[grad_indx]\n",
    "    \n",
    "    #this_loss = []\n",
    "    \n",
    "    for j,x_prime in enumerate(dt_y_hat):\n",
    "        \n",
    "        label = cols[1:][j]\n",
    "        num_labels = [map_dicts_v2[label][f] for f in ys[j]]\n",
    "        hl1_this[:,j] = neuron_l1(x_prime,w1[j],b1[j],num_labels)\n",
    "        \n",
    "    this_loss = np.mean(hl1_this,axis = 0)\n",
    "    #print(this_loss.shape)\n",
    "    if i % 50 == 0 or i == iterations-1:\n",
    "        print('Iteration {}:'.format(i+1))\n",
    "        for m, loss_part in enumerate(this_loss):\n",
    "            print('\\tAttribute {}: {:0.4f}'.format(m+1,loss_part))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_norm = []\n",
    "\n",
    "for i, clf in enumerate(clfs):\n",
    "    dt_norm.append(clf.predict_proba(xs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl1_this_all = np.zeros((len(df_oc_oh),len(cols[1:])))\n",
    "preds = []\n",
    "\n",
    "for j,x_prime in enumerate(dt_norm):\n",
    "        \n",
    "        label = cols[1:][j]\n",
    "        num_labels = [map_dicts_v2[label][f] for f in ys[j]]\n",
    "        \n",
    "        preds.append(neuron_l1(x_prime,w1[j],b1[j],num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute 1: Score 0.9093\n",
      "Attribute 2: Score 0.9522\n",
      "Attribute 3: Score 0.8367\n",
      "Attribute 4: Score 0.9116\n",
      "Attribute 5: Score 0.9628\n",
      "Attribute 6: Score 0.9137\n",
      "Attribute 7: Score 0.8358\n",
      "Attribute 8: Score 0.5387\n",
      "Attribute 9: Score 0.9551\n"
     ]
    }
   ],
   "source": [
    "for i,this_pred in enumerate(preds):\n",
    "    print('Attribute {}: Score {:0.4f}'.format(i+1,np.mean(this_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8684455981977158"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomalous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_anom = []\n",
    "ys_anom = []\n",
    "\n",
    "for col in cols[1:]:\n",
    "    \n",
    "    this_X = df_anom_oh.loc[:,[f for f in df_anom_oh.columns if not f.startswith(col)]]\n",
    "    this_y = df.loc[:,col]\n",
    "    \n",
    "    xs_anom.append(this_X)\n",
    "    ys_anom.append(this_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_anom = []\n",
    "\n",
    "for i, clf in enumerate(clfs):\n",
    "    dt_anom.append(clf.predict_proba(xs_anom[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl1_this_anom = np.zeros((len(df_anom_oh),len(cols[1:])))\n",
    "preds_anom = []\n",
    "\n",
    "for j,x_prime in enumerate(dt_anom):\n",
    "        \n",
    "        label = cols[1:][j]\n",
    "        num_labels = [map_dicts_v2[label][f] for f in ys_anom[j]]\n",
    "        \n",
    "        preds_anom.append(neuron_l1(x_prime,w1[j],b1[j],num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute 1: Score 0.6013\n",
      "Attribute 2: Score 0.5484\n",
      "Attribute 3: Score 0.6555\n",
      "Attribute 4: Score 0.8197\n",
      "Attribute 5: Score 0.7088\n",
      "Attribute 6: Score 0.5300\n",
      "Attribute 7: Score 0.5282\n",
      "Attribute 8: Score 0.5857\n",
      "Attribute 9: Score 0.7611\n"
     ]
    }
   ],
   "source": [
    "for i,this_pred in enumerate(preds_anom):\n",
    "    print('Attribute {}: Score {:0.4f}'.format(i+1,np.mean(this_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6376266095941842"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(preds_anom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28766319, 0.10338632, 0.62942155, 0.28946381, 0.11335123,\n",
       "       0.1094798 , 0.07664245, 0.29747496, 0.05860824])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_norm = []\n",
    "\n",
    "for i, clf in enumerate(clfs):\n",
    "    dt_norm.append(clf.predict_proba(xs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl1_this_all = np.zeros((len(df_oc_oh),len(cols[1:])))\n",
    "preds = []\n",
    "\n",
    "for j,x_prime in enumerate(dt_norm):\n",
    "        \n",
    "        label = cols[1:][j]\n",
    "        num_labels = [map_dicts_v2[label][f] for f in ys[j]]\n",
    "        \n",
    "        preds.append(neuron_l1(x_prime,w1_init[j],bias_init[j],num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute 1: Score 0.6912275403955102\n",
      "Attribute 2: Score 0.7199679688193054\n",
      "Attribute 3: Score 0.6202717966617182\n",
      "Attribute 4: Score 0.6913042905024895\n",
      "Attribute 5: Score 0.728418202635014\n",
      "Attribute 6: Score 0.6907720864305099\n",
      "Attribute 7: Score 0.63777535255288\n",
      "Attribute 8: Score 0.4731615902507555\n",
      "Attribute 9: Score 0.7214147839299194\n"
     ]
    }
   ],
   "source": [
    "for i,this_pred in enumerate(preds):\n",
    "    print('Attribute {}: Score {}'.format(i+1,np.mean(this_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6638126235753448"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl1_this_anom = np.zeros((len(df_anom_oh),len(cols[1:])))\n",
    "preds_anom = []\n",
    "\n",
    "for j,x_prime in enumerate(dt_anom):\n",
    "        \n",
    "        label = cols[1:][j]\n",
    "        num_labels = [map_dicts_v2[label][f] for f in ys_anom[j]]\n",
    "        \n",
    "        preds_anom.append(neuron_l1(x_prime,w1_init[j],bias_init[j],num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute 1: Score 0.5332323086324527\n",
      "Attribute 2: Score 0.5390414314870995\n",
      "Attribute 3: Score 0.5093692540191332\n",
      "Attribute 4: Score 0.6309784608815728\n",
      "Attribute 5: Score 0.591314281673475\n",
      "Attribute 6: Score 0.526431575470484\n",
      "Attribute 7: Score 0.5153265172539562\n",
      "Attribute 8: Score 0.5058281045548834\n",
      "Attribute 9: Score 0.620899902587802\n"
     ]
    }
   ],
   "source": [
    "for i,this_pred in enumerate(preds_anom):\n",
    "    print('Attribute {}: Score {}'.format(i+1,np.mean(this_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5524913151734288"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(preds_anom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
